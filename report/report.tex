\documentclass[10pt]{report}

\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage[english]{babel}
\usepackage[left=2cm,top=1.5cm,right=2cm,bottom=2cm]{geometry}

\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsopn}
\usepackage{amsthm}
\usepackage[hidelinks]{hyperref}
\usepackage{cleveref}
\usepackage{fancyvrb}
\usepackage{tikz}
\usepackage[justification=centering]{caption}
% \patchcmd{\thebibliography}{\chapter*}{\section*}{}{}
\usepackage[super]{nth}
\usepackage{textcomp}
\usepackage{enumitem}
\usepackage{doi}
\usepackage{mathrsfs}
\usepackage{siunitx}
\setlist{nosep}


\theoremstyle{plain}
\newtheorem{thm}{Theorem}[chapter]
\newtheorem{prop}[thm]{Property}
\newtheorem{lem}[thm]{Lemma}
\newtheorem{cor}{Corollary}[thm]

\theoremstyle{definition}
\newtheorem{defn}{Definition}[chapter]
\newtheorem{axi}{Axiom}[chapter]
\newtheorem{eqn}[thm]{Equation}

\theoremstyle{remark}
\newtheorem*{rem}{Remark}


\setcounter{secnumdepth}{3}
\setcounter{tocdepth}{1}
%\renewcommand\thesection{\arabic{section}}

\newcommand{\R}{\ensuremath{\mathbb{R}}}
\newcommand{\Rb}{\ensuremath{\overline{\mathbb{R}}}}
\newcommand{\N}{\ensuremath{\mathbb{N}}}
\newcommand{\Q}{\ensuremath{\mathbb{Q}}}
\newcommand{\Z}{\ensuremath{\mathbb{Z}}}
\newcommand{\C}{\ensuremath{\mathbb{C}}}
\newcommand{\U}{\ensuremath{\mathbb{U}}}
\newcommand{\F}{\ensuremath{\mathbb{F}}}
\newcommand{\K}{\ensuremath{\mathbb{K}}}
\newcommand{\TODO}{\textbf{TODO}}


\newcommand\eqdef{\stackrel{\mathclap{\mbox{\tiny def}}}{=}}


\sisetup{inter-unit-product=\ensuremath{{}\cdot{}}}

\newcommand{\ket}[1]{|#1\rangle}
\newcommand{\bra}[1]{\langle#1|}
\newcommand{\braket}[2]{\langle#1|#2\rangle}

\newcommand{\dd}{\mathrm{d}}
\newcommand{\der}[2]{\frac{\dd{#1}}{\dd{#2}}}
\newcommand{\dern}[3]{\frac{\dd^{#3} #1}{\dd{#2}^{#3}}}
\newcommand{\dpar}[2]{\frac{\partial{#1}}{\partial{#2}}}
\newcommand{\dparn}[3]{\frac{\partial^{#3} {#1}}{\partial{#2}^{#3}}}

\renewcommand{\geq}{\geqslant}
\renewcommand{\leq}{\leqslant}

\newcommand{\mat}[1]{\begin{pmatrix}#1\end{pmatrix}}
\newcommand{\bs}{\boldsymbol}

\DeclareMathOperator{\cov}{cov}
\DeclareMathOperator{\Tr}{Tr}
\DeclareMathOperator{\argmax}{arg\,max}
\DeclareMathOperator{\argmin}{arg\,min}
\DeclareMathOperator{\rk}{rk}
\DeclareMathOperator{\Span}{Span}
\DeclareMathOperator{\dom}{dom}


\newcommand{\class}[1]{{\mathscr{C}^{#1}}}




\newcommand{\ml}{_{M\!L}}


\newcommand{\maxim}[3]{\begin{cases}
    \mathbf{maximize}\,\quad #1& \mathbf{on}\; #2\\
    \mathbf{subject\;to}\quad #3
  \end{cases}}
\newcommand{\maximf}[2]{\begin{cases}
    \mathbf{maximize}\,\quad #1& \mathbf{on}\; #2
  \end{cases}}
\newcommand{\maxima}[3]{\begin{cases}
    \mathbf{maximize}\,\quad #1& \mathbf{on}\; #2\\
    \mathbf{subject\;to}\quad \begin{aligned}[t]#3\end{aligned}
  \end{cases}}

\newcommand{\minim}[3]{\begin{cases}
    \mathbf{minimize}\;\,\quad #1& \mathbf{on}\; #2\\
    \mathbf{subject\;to}\quad #3
  \end{cases}}
\newcommand{\minimf}[2]{\begin{cases}
    \mathbf{minimize}\,\quad #1& \mathbf{on}\; #2
  \end{cases}}
\newcommand{\minima}[3]{\begin{cases}
    \mathbf{minimize}\;\,\quad #1& \mathbf{on}\; #2\\
    \mathbf{subject\;to}\quad \begin{aligned}[t]#3\end{aligned}
  \end{cases}}






% \usepackage{titlesec}
% \titleformat{\chapter}[hang] 

% \makeatletter
% \def\@makechapterhead#1{%
%   \vspace*{0\p@}% %%% removed!
%   {\parindent \z@ \raggedright \normalfont
%     \ifnum \c@secnumdepth >\m@ne
%         \huge\bfseries \@chapapp\space \thechapter
%         \par\nobreak
%         \vskip 10\p@
%     \fi
%     \interlinepenalty\@M
%     \Huge \bfseries #1\par\nobreak
%     \vskip 30\p@
%   }}
% \def\@makeschapterhead#1{%
%   \vspace*{0\p@}% %%% removed!
%   {\parindent \z@ \raggedright
%     \normalfont
%     \interlinepenalty\@M
%     \Huge \bfseries  #1\par\nobreak
%     \vskip 30\p@
%   }}
% \makeatother

% \usepackage{titlesec}
% \titlespacing*{\section}{0pt}{.7\baselineskip}{.5\baselineskip}
% \titlespacing*{\subsection}{0pt}{.4\baselineskip}{.3\baselineskip}

\begin{document}

\begin{titlepage}
  \centering
  {\scshape\huge École Normale Supérieure \par}
  \vspace{0.3cm}
  {\scshape\Large Department of Mathematics and their Applications (DMA) \par}
  \vspace{3cm}
  {\Huge\bfseries Error estimation in maxlike reconstruction for quantum tomography \par}
  \vspace{0.5cm}
  {\scshape\Large Internship report\par}
  \vspace{3cm}
  {\LARGE Thibaut \textsc{Pérami}\par}
  \vfill
  {
    \large
    supervised by\par
    Igor \textsc{Dotsenko}\par
    and\par
    Pierre \textsc{Rouchon}\par
  in\par
  LKB, Collège de France
  }

  \vfill

  % Bottom of the page
  {\Large \today\par}
\end{titlepage}

\newcommand{\fset}{\ensuremath{\mathop{\text{\textquotesingle}}}}


% \pagenumbering{gobble} % to avoid counting contents page in report
\tableofcontents

\chapter*{Introduction}
% \pagenumbering{arabic}
\addcontentsline{toc}{chapter}{Introduction}

This report details my internship with Pierre Rouchon and Igor dotsenko on
Quantum tomography by maximum-likelihood reconstruction. It was done mainly at
the Laboratory Kessler-Brosel (LKB) in the Collège de France.

The goal of Quantum tomography is to find ways to reconstruct the state of
a quantum system from several direct or indirect measurement on it. In some case
those measurement do not modify the state of the system. Those are called QND
(Quantum Non-Destructive) measurement.

The specific physical project on which I worked with Igor Dotsenko is the
internship project of Luis Najera about thermodynamics in the case of
atom-cavity interaction in quantum optics. More precisely, we send an circular
Rydberg atom in a resonant cavity containing photons. The state of the cavity is
thermal i.e it follow the Bose-Einstein distribution. The atom then interacts
with the cavity. If the atom is in a thermal state between two atomic level that
are at the same frequency than the cavity then a thermal exchange will occur in
the expected way. However if we pump one of the state of the atom in a hidden
state, like a Maxwell demon, we can can apparently break the second law and make
a cold atom give head to a hotter cavity.

In order to study this experiment, we need to measure the state of the cavity.
That state cannot be measured directly, so we do it by quantum tomography using
maximum-likelihood reconstruction. This construction takes into account all the
measurements made and deduce a density matrix. To find it, one needs to solve a
convex optimisation problem on the set of density matrix (hermitian positive
definite matrix of trace 1). This was done using a gradient descent method with
projection of the gradient on the domain.

The deduced state is usually not a pure state because the reconstruction often
came from a state that has been prepared several times.
All the prepared state are slightly different.
Furthermore, other factors like measurements imperfection and decoherent
relaxation decrease the precision of the reconstruction.

With this measurements, we can now get and interpret the results of our Maxwell
demon experiment. However, to be able to interpret measurement, we need to know
the error on the reconstructed state. The original paper [ref here] on
tomography only provide the standard deviation of usual quantum operator which
are linear in the density matrix. However to do our analysis of the second law,
we need to evaluate the error on the entropy.

In order to do that, I had to extract from the reconstruction the probability
distribution around the maximum which is our estimator. But this distribution
cannot be samples easily because its a mix of Gaussian and exponential law
truncated into the domain of density matrix. Into to sample from this
probability I use an adapted hit and run method to build a Markov chain on the
density matrix space (but discrete time) whose stationary distribution is the
wanted distribution. By sampling this chain long enough, I can get the statistic
average and standard deviation of any real function of the density matrix space.

In the end we get nice plots with errorbars and we were able to determine which
point we realistic within the error-bars and which were completely wrong. We
could then redo the bad point and reach a clean conclusion.

\

This report alternate maths and physics. The odd chapters are about the physical
part of the internship and the even ones about maths. The five first chapter are
about my understanding of prior work that I had to do in order to do what I did.
The last two are about my personal contributions.

In the first chapter I
present the experiment, its modelisation and what we want to prove. In the
second I explain the basics of maximum likelihood reconstruction then I show in
the third chapter how to apply this method for our particular case. In the
fourth chapter I show how to solve the convex optimization problem. Then I can
explain the state of the results before I arrived in chapter 5. In chapter 6 I
explain what I did for computing errorbars for non-linear function and at last
I explain the final results in chapter 7.

\vfill

\paragraph{Notations:} I'll use the bra-ket notation and thus my Hilbertian
products are linear on the right. On $\R^n$ I'll use $>$ and $\geq$ for
component wise inequality. On $\mathcal{M}_n(\C)$, $A > B$ mean that $A-B$ is hermitian
positive definite and $A \geq B$ means that $A - B$ is hermitian positive
semi-definite. This works obviously also on $\mathcal{M}_n(\R)$. The conjugate will be
denoted by $A^*$, the transpose by $A^t$, and the transpose conjugate by
$A^\dagger$. The same notations will be used on any self-operator space of any finite dimension
Hilbert space.


\chapter{Experimental setup and goal}

In this chapter I expect a basic knowledge of quantum mechanics, Hilbert space and
Schrodinger equations. In the while report I will use the usual bra-ket notation
and therefore a scalar product linear to the right.

I will first describe the experiment in high-level point of view, then I'll
quickly dive into experimental details I'll finish by explaining why
reconstruction is needed.

\section{Basic setup description}

In this section I will describe the experiment I worked with at the LKB.\@This
experience studies the interaction between Rydberg circular atoms and light in
cavities.
We produce Rydberg atoms in a known state, then we send them through a
cavities with a very small number of resonating photons (usually less than
eight). The atom then goes through a detector that ideally do projectile
measurement of the state. The cavity can be tune via stark effect so the
interaction can be resonant (the cavity frequencies correspond to a gap between
states) or diffusive (The frequencies and the gap do not match).

I will present the formalism for each component and then detail the formalism of
the whole experiment. The goal of the experiment is to study quantum
thermodynamics. In particular, with the right manipulation of the quantum state
of an atom, we can make give heat to the cavity (emit a photon) even if the atom
is colder than the cavity. I will define the notion of temperature of single
atom later.

Most of the formulas come from~\cite{Har06}


\subsection{Rydberg Ciruclar atoms}

The atoms are prepared in a specific circular Rydberg state called ground state
$\ket g$. It correspond the energy level $n = 50$. We will also use $\ket e$
called excited state which is the circular state at $n = 51$ and $\ket f$, the
``fundamental state'' which is at $n = 49$. In theory the atom should never get
in any other state during our protocol.
The gap between $\ket e$ and $\ket g$ is
approximately $\SI{51}{GHz}$, whereas the gap between $\ket g$ and $\ket f$ is
around $\SI{49}{GHz}$.

In most of our calculation we will manipulate our states by pairs, and not as the
whole triplet, because each interaction the atom will do with our setup, will be
done at, or near a resonance frequency. In such case, the Hamiltonian we will
use is:
\[H = \frac {\hbar \omega}2 \sigma_Z\]
 where $\omega$ is the gap frequency and $\sigma_Z$ in one of the
 three Pauli matrices used in two-levels systems:
\[\sigma_Z = \mat{1&0\\0&1} \quad \quad \sigma_X = \mat{0&1\\1&0} \quad \quad
  \sigma_Y = \mat{0&-i\\i&0}\]

It is important to note that the $X,Y,Z$ axis here have nothing to do with the
real world spatial axis but there are just a convention due to the fact that
this two-level system looks a spin-system, where those axis would have had a
spatial meaning.

From those operator we may also build the raising and lowering operators:
\[\sigma_+ = \frac{\sigma_X + i \sigma_Y}2 = \ket 1 \bra 0 \quad \quad \quad \quad
  \sigma_- = \frac{\sigma_X - i \sigma_Y}2 = \ket 0 \bra 1\]

Those operator are the equivalent of anihilation and creation operator in usual
harmonic oscillator (That I will present in \cref{ssec:rescav}). We can even
express the Hamiltonian in a similar way, $H = \hbar \omega(\sigma_+\sigma_- - \frac12)$




\subsection{Ramsay zone: Interaction with classical field}

In what we call Ramsay zone, the atom will be submitted to a classical oscillating
field, resonant with the transition. I'll use $\ket e$ and $\ket g$ has my
excited and normal states, but it works the same The field at the position of the atom will
be denoted by:

\[\bs E = \mathcal{E}
  \mat{u_x\sin(\omega_f t + \varphi + \varphi_x)\\
    u_y\sin(\omega_f t + \varphi + \varphi_y)\\
    u_z\sin(\omega_f t + \varphi + \varphi_z)}\]
where $u_x^2 + u_y^2 +u_z^2 = 1$. We do not merge the global phase $\phi$ into
the component phase to be able to use it later. This can be represented more
cleanly using $\bs u_f = \big(u_x e^{i\varphi_x},u_y e^{i\varphi_y},u_z
e^{i\varphi_z}\big)$:
\[\bs E = i\mathcal{E} (\bs u_f\, e^{-i\omega_f t-\varphi} - \bs u_f^*\,
  e^{i\omega_f t + \varphi})\]

With that field we can now express the Hamiltonian $H_f$ of the
interaction between the electric dipole of the
atom and the electric field. It is $H_f = - \bs D \cdot \bs E$.
The dipole operator has a simple expression in terms
of the position operator $\bs R$ of the electron which is $\bs D = q \bs R$.
In our circular states, we have $\bra e R \ket e = 0$ and $\bra g R \ket g = 0$,
so we only care about the off diagonal terms. We want to write the dipole
operator as:
\[\bs D = d\mat{\bs 0&\bs u_a^*\\\bs u_a&\bs 0}\]
Such that $\bs u_a$ expressed the direction and $d$ the value of electric dipole
moment. They are defined by $ q \bra g \bs R \ket e = d \bs u_a$. The field
Hamiltonian has now the expression:

\[ H_f = id\mathcal{E} \mat{\bs 0 &
  \bs u_a^* \cdot (\bs u_f\, e^{-i\omega_f t-\varphi} - \bs u_f^*\,
  e^{i\omega_f t + \varphi})\\
\bs u_a \cdot (\bs u_f\, e^{-i\omega_f t-\varphi} - \bs u_f^*\,
  e^{i\omega_f t + \varphi}) & \bs 0
}\]

\

The free Hamiltonian of the system being $H_a = \frac{\hbar \omega_a}2 \sigma_Z$.
We'll need to express the evolution of the system by separating both evolutions.
We will place ourselves in an interaction picture (explanation
in~\cref{app:pict}). Both the free and interaction Hamiltonian make the state turn
around, We want to see the difference between the two of them. Therefore, We
will remove $H_0 = \frac{\hbar \omega_r}2 \sigma_Z$. We remove the Hamiltonian
with the frequency of the field and not the atom to simplify the field
frequencies elsewhere. Our new Hamiltonian $H_1 = e^{i\frac{H_0}\hbar t}(H_f + H_a - H_0)e^{i\frac{H_0}\hbar t}$ is thus:
\[H_1 =  \]

\subsection{Resonant cavities}\label{ssec:rescav}

Harmonic oscillator.

\subsection{Atom-cavity interaction}

\subsection{Protocol}

From Luis notes.


\section{Experimental details and calibration}

From Clement's thesis

\subsection{State preparation}

% oven
% speed filtering Laser with doppler + resonnance
% State filtering (n=52)
% We ignore non-Rydeberg atoms

\subsection{Detection of atom}

% see thesis for functioning of detector

\subsection{Cooling and relaxation times}

% Say some stuff about cooling

\section{Reconstruction}

Still from~\cite{Har06} and Clement's thesis

\subsection{Ramsay interferometer}

\subsection{Phase shift of QND atoms}

\subsection{What data we have as an output}

Personal





\chapter{Maximum likelihood reconstruction}

I put some reminders about multivariate covariances in
\cref{app:cov}, which could be useful in this chapter.

\section{Reminders about estimation theory}

\subsection{Estimator}

The goal of estimation is to estimate some parameters using observations or
measurements. In the simplest case, we measure an random output $X \in \mathcal{X}$ from an
unknown input $\theta \in \Theta$. We place ourselves in a model where the law
of X condition to $\theta$ is known. Formally, We have for each $\theta$ a
probability measure $P_\theta$ on $\mathcal{X}$. If $P_\theta$ has the right
form (in particular if $X$ is a vector of repetition of the same experiment), we
can extract information on $\theta$ from $X$. For that we can use an estimator.

\begin{defn}
  An \emph{estimator} of parameter $\theta$ from $X$ is just a deterministic
  function $\hat \theta(X)$ that tries to give the most likely $\theta$ that
  could have outputted $X$.
\end{defn}

\begin{rem}
  The estimator notation $\hat \theta$ has noting to do with the notation of
  quantum operator in quantum mechanics. It should usually be clear from the
  context which one it is.
\end{rem}

\

The most current case of parameter is $\theta \in \R$. In that case we can
easily compare the original $\theta$ with its estimator $\hat \theta$ with a
subtraction:

\begin{defn}
  For a given $\theta$, the \emph{bias} of the estimator $\hat \theta$ is:
  \[B(\hat{\theta}) = E_\theta(\hat{\theta}(X) - \theta)\]
  where the expectation $E_\theta$ is taken on the law $P_\theta$. An estimator
  is \emph{biased} is the bias is non zero and \emph{unbiased} otherwise.
\end{defn}

\begin{defn}
  For a given $\theta$, the \emph{variance} of the estimator $\hat \theta$ is:
  \[V(\hat{\theta}) = E_\theta\Big({(\hat{\theta}(X) - \theta)}^2\Big)\]
\end{defn}

\subsection{Likelihood}

In the case where all probability measure $P_\theta$ are absolutely
continuous against a ``canonincal'' measure $\mu$ on $\mathcal{X}$, we can
define a function $f(x;\theta)$ such that
\[P_\theta(A) = \int_A f(x;\theta)\,\dd \mu(x)\]

\begin{defn}
  For a given observation $x \in \mathcal{X}$, we define the \emph{likelihood} function
  $\mathcal{L}_x(\theta) = f(x;\theta)$.
\end{defn}

\begin{defn}
  For a given observation $x \in \mathcal{X}$, we define the \emph{log-likelihood} function
  $\ell_x(\theta) = \ln \mathcal{L}_x(\theta)$.
\end{defn}

\subsection{Fischer information and Cramér-Rao bound}

We now assume a set of real parameter $\theta \in \mathcal{D} \subset \R^n$.

A way of knowing if we could improve our estimation at a specific point is the
gradient of the log-likelihood function. This is called the
\emph{score}. We have $s_x(\theta) = \partial_\theta \ell_x(\theta)$. The
lower the score (its norm, actually), the better our estimation.

As we move around the optimal likelihood value \TODO{} bullshit

\begin{prop} The expectation of the score is 0.
\end{prop}
\begin{proof}
  \TODO{}
\end{proof}

We can then study the variance of score. The lower this variance is, The more
$\theta$ value \TODO{} bullshit

We can then make an important remark

\begin{lem}\label{lem:corscr}
  The covariance of the score and any unbiased estimator is the identity.
  Formally: $\cov(\hat \theta, s_x(\theta)) = I$
\end{lem}

\begin{proof}
  \TODO{}
\end{proof}

In light of the theorem about bounds of \cref{sec:correl}, we can give special
interest to the variance of the score and its link with the variance of any estimator

\begin{defn} The \emph{Fischer Information} of the parameter $\theta$ is defined
  as the variance of the score:
  \[I(\theta) = V\big(s(\theta)\big)\]
\end{defn}

If $\theta \in \R$, this is just the expectation of the square of the score, but
otherwise. $I(\theta)$ is a covariance matrix thus at least positive
semi-definite.
This information value is putting a bound on the minimum variance of any
unbiased estimator which is called the Cramér–Rao bound.

\begin{thm}[Cramér–Rao bound]
  For any un-biased estimator $\hat \theta$, If $I(\theta) > 0$, we have
  \[V(\hat{\theta}) \ge {I(\theta)}^{-1}\]
\end{thm}

\begin{rem}
  In the multivariate case, the ${}^{-1}$ obviously means the inverse of the matrix
\end{rem}

\begin{proof}
  The bound on multivariate correlation is proven in \cref{thm:correln}. The
  bound is written as:
  \[\cov(X,Y){V(Y)}^{-1}\cov(Y,X) \leq V(X)\]

  As $I(\theta) = V(s_x(\theta))$, and thank to \cref{lem:corscr}, the bound holds.
\end{proof}

In order to have a better interpretation of Fischer information, if the
likelihood is at least $\class 2$ in $\theta$, we can rewrite
it as a hessian:

\begin{prop}
  Under sufficient regularity assumption,
  the Fischer information can also be written as the opposite of the Hessian of the
  log-likelihood function.
  \[I(\theta) = -\frac{\partial^2 \ell}{\partial \theta^2}(\theta)\]
\end{prop}

\begin{proof}
  TODO
\end{proof}







\section{Maximum likelihood estimator}

\subsection{Definition}

Now that we have proven the best variance possible, We still have to build an
estimator that approach this bound. There are multiple kind of estimator. The
one mostly used is the average when $X = (X_1,\ldots,X_n)$ and
$E_\theta(X_i) = \theta$ and $V_\theta(X_i)$ is small enough. However in more
complex case this wont work. The goal of the estimator is to produce the more
likely $\theta$, ideally the maximum of a density function $p(\theta | X)$.
Thanks to bayes law, we have (if all measure can be expressed as density
function \textbf{TODO} put that first):
\[p(\theta|x) = p_\theta(x) \frac {p(\theta)}{p(x)}
  = p_\theta(x) \frac {p(\theta)}{\int p_{\theta'}(x)p(\theta')\,\dd \theta'}\]

And our goal would be to maximize $p(\theta|x)$. However,in order for that
formula to make sense, we need a prior law on $\theta$. If the prior
distribution is more or less uniform, it is the same as maximizing $p_\theta(x)
= \mathcal{L}_x(\theta)$.


\begin{defn}
  The \emph{maximum likelihood estimator} $\theta\ml$ is defined by:
  \[\theta\ml(x) = \argmax \mathcal{L}_x\]
\end{defn}

The maximum likelihood do not have excessively nice properties in its own, but
when $X = (X_1,\ldots,X_n)$ where all the $X_i$ come from the same law
$P_\theta(X_0)$ and are independent and $n \to \infty$,
we will have nice convergence properties. In particular, it will converge in
probability to the right
$\theta$ and saturate the Cramér-Rao bound as $n \to \infty$. I will prove that
claim in our specific context in chapter 6 \textbf{TODO} proper reference.

\

In practice, as most probability laws are log-concave (in particular the normal
law), we will use the log-likelihood, $\ell_x$ instead of $\mathcal{L}_x$. Apart
from concavity, this also has the advantage that multiple repetition are
additive instead of multiplicative:
\[\mathcal{L}_x(\theta) = \prod_i \mathcal{L}_{x_i}(\theta) \quad \quad \quad
  \quad \ell_x(\theta) = \sum_i \ell_{x_i}(\theta)\]

In particular, as probability goes down to zero quickly and we will be working on
64 bits machine floating point numbers. There is a high risk of $\mathcal{L}$ to
be simply computed to zero on the machine when it is just really small. For
information the natural logarithm of the minimum positive 64 bits floating point number
is $-740$.

\subsection{Informal properties}

Put the probability function according to Vincent's thesis.

Add the case at the edge of $\mathcal{D}$.

\chapter{Effect matrices computation}

In this chapter, we stay in Hilbert spaces of finite dimension. Most of the
result can be extended to Hilbert spaces of countable dimension, by adding
some restriction,
but we won't need then in the rest of the report, so I won't mention infinite
dimension anymore. The space of operator on
$\mathcal{H}$ is denoted by $\mathcal{L}(\mathcal{H})$. The set of observable
(Hermitian operators) is denoted by $\mathcal{O}(\mathcal{H})$. The set of
unitary operator on $\mathcal{H}$ is denoted by $\mathcal{U}(\mathcal{H})$.

\section{Density matrices}

\subsection{Justification}

In order to make significant observation on an experimental setup that has a lot
of errors everywhere, we need to make averages and statistics on quantum state.
One way of doing that would be to manipulate probability measure over state
space which is the unit sphere $S$ of the model Hilbert space $\mathcal{H}$. However if we look at
it in details, there are a lot of distributions that indistinguishable by any
measurement. In first approximation, we say that two probability distribution
$\lambda$ and $\mu$ on $S$ are indistinguishable,
if for any observable $A$ (Hermitian matrix) on $\mathcal{H}$, we
have:

\[\int_S \bra \phi A \ket \phi\,\dd \lambda(\phi) = \int_S \bra \phi A \ket
  \phi\,\dd \mu(\phi) \]

However, if we rewrite it, we have:

\[\int_S \bra \phi A \ket \phi\,\dd \lambda(\phi)
  = \int_S \Tr\big(\ket \phi \bra \phi A\big) \,\dd \lambda(\phi)
  = \Tr\left(\int_S \ket \phi \bra \phi \,\dd \lambda(\phi) A \right)\]

\begin{defn} We define the density matrix of a probability distribution $\lambda$ on
  quantum states:
  \[ \rho = \int_S \ket \phi \bra \phi \,\dd\lambda(\phi) \]
\end{defn}
\begin{prop}
  The average of an observable $A$ in any probability distribution $\lambda$ is
  given by $\Tr(\rho A)$
\end{prop}

\begin{rem} This is sufficient to fully characterise the distribution, because
 any observable $A$ can be written $A = \sum_a aP_a$, where $P_a$ are orthogonal
 projector who are also observable. The average of $P_a$ is $\Tr(\rho P_a)$ and
 thus for all the distribution that have density matrix $\rho$, The probability
 of output $a$ when we measure $A$ is the same.
\end{rem}

Therefore in the rest of this report, we will use density matrix as the only
representation of quantum distribution, as two distribution that share the same
density matrix are completely indistinguishable by any measurement. In practice,
as quantum physicist, manly manipulate probabilistic quantum state and not that
much usual \emph{ket} state, the term quantum state is used for a statistical
mixture described by a density matrix. A state of the form $\ket \phi$ is thus
called a \emph{pure} state.

\subsection{Properties}

We can now study what are density matrices and find necessary and sufficient
conditions for a matrix to be density matrix.

\begin{prop}\label{prop:dens}
  A density matrix is Hermitian positive ($\rho > 0$) of trace 1
\end{prop}

\begin{proof}
  $\ket \phi \bra \phi > 0$, so $ \int_S \ket \phi \bra \phi \,\dd\lambda(\phi)
  > 0$.
  $\Tr(\ket \phi \bra \phi) = 1$, so $\Tr(\rho) = \lambda(S) = 1$
\end{proof}

If we want to prove that is sufficient we need to look at the spectral
decomposition.
In finite dimension $n$, a spectral decomposition of $\rho$ give a
collection of eigen values $p_1, \ldots, p_n$ whose sum is~1. Those are the
analogous of probabilities in classical probability theory. The density matrix
can then be written:
\[\rho = \sum p_i \ket {\phi_i} \bra {\phi_i}\]

\begin{thm} The condition~\ref{prop:dens} is necessary and sufficient i.e any Hermitian positive matrix of trace 1 is a density matrix.
\end{thm}

\begin{proof}
  Any matrix satisfying the condition~\ref{prop:dens} can be decomposed in
  $\rho = \sum p_i \ket {\phi_i} \bra {\phi_i}$, and thus the atomic measure
  $\lambda(\{\ket {\phi_i}\}) = p_i$ give exactly that density matrix.
\end{proof}

The set of density matrix will be denoted by $\mathcal{D}(\mathcal{H})$ (or just
$\mathcal{D}$ when there is no ambiguity). We have the inclusions:
\[\mathcal{D}(\mathcal{H}) \subset \mathcal{O}(\mathcal{H}) \subset \mathcal{L}(\mathcal{H})\]

As a density matrix is an observable, we can study its behavior as an observable.
In state $\ket \Psi$, the average $\langle \rho \rangle$ is the probability of
state $\ket \Psi$ if we did a projective measurement in an orthonormal base that
contains $\ket \Psi$. $\rho$ is thus like an observable of classical probability.

\subsection{Rank and purity}

In finite dimension, we can also look at the
rank of the density matrix that gives a lot of information.

\begin{prop}
  The rank of the density matrix $\rho$ is the dimension of the support of any
  probability distribution that can give this matrix
  (with the convention $\dim A = \dim \Span(A)$).
\end{prop}

\begin{proof}
   \TODO
\end{proof}

\begin{defn}
  If a density matrix $\rho$ has rank one, it only represents one unique state and can be written
  $\rho = \ket \phi \bra \phi$. It is thus called a \emph{pure state}. No
  difference is made between the state $\ket \phi$ and the density matrix $\ket
  \phi \bra \phi$ as both are called pure states.

  On the other hand if $\rk \rho > 1$, the density matrix represent a
  \emph{mixed state}: a statistical mixture of state.
\end{defn}

\begin{rem}
  It is very important to differentiate the quantum superposition, for example
  on qubit,
  $\ket + = \frac1{\sqrt 2} \ket 0 + \frac1{\sqrt2} \ket 1$ and a statistical mixture of
  $50$ \% of $\ket 0$ and $50$\% of $\ket 1$. When the state in measured in base
  $\ket0,\ket1$, the results will be the same but in other base they could be
  different. In particular, in base $\ket +, \ket -$, the first one will be
  measured as $100$ \% $\ket +$ and $0$ \% $\ket -$ but the second will still be
  50\,--\,50 of $\ket+$ and $\ket -$.
\end{rem}

\begin{prop}
  A state $\rho$ is pure iff $\Tr \rho^2 = 1$.
\end{prop}

\begin{proof}
   \TODO
\end{proof}

The value $\Tr \rho^2$ has in fact much more interesting properties, and thus
deserves a name.

\begin{defn}
  The \emph{purity} of a quantum state represented by $\rho$ is the value $\gamma = \Tr \rho^2$.
\end{defn}

\begin{prop}
  In dimension $d$, the purity is always between $\frac1d$ and $1$. If $\gamma =
  \frac1d$, then $\rho = I$ and the mixture represented is uniform, we have
  absolutely no information on the state. If $\gamma = 1$, The state is pure and
  we thus have complete information on the quantum state.
\end{prop}

\begin{proof}
   \TODO
\end{proof}

The main interest of purity is that it remains constant in unitary evolution
($\Tr (U^\dagger \rho U) = \Tr \rho^2$),
whereas it will change in any other evolution, relaxation, decoherence,
measurement, as we lose information or gain information.

\subsection{Coefficients interpretation}

When we express the density matrix in a specific base, we gain a lot of
information about the state projected in that base, in particular about how
projective measurements in that base will happen.

\begin{defn}
  When $\rho$ is express in the base $\ket 1, \ldots, \ket d$, the diagonal
  coefficients which are real, are called \emph{populations}, because the
  coefficient $\bra i \rho \ket i$ is the probability of measuring state $i$,
  when measuring in that base.

  The non-diagonal coefficient are complex and named \emph{coherence}. The
  coherence between state $\ket i$ and state $\ket j$ is $\bra i \rho \ket j$
  and is the conjugate of the coherence between $\ket j$ and $\ket i$.
\end{defn}

The point of this distinction is that any projective measurement made in that
base will have the same statistics whatever the value of coherences. Their
values, will only matter when measuring value in other bases or when the state
is evolving. This also means reciprocally, in the context of tomography,
that measurements made in that base can bring no information.

As we will reconstruct $\rho$, numerically we will use this matrix
representation, we need to study the structure of $\mathcal{D}(\mathcal{H})$ in
this form. In particular:

\begin{prop}
  $\dim \mathcal{D}(\mathcal{H}) = d^2 - 1 $ as a real vector space.
\end{prop}

\begin{proof}
  The (real) dimension of $\mathcal{O}(\mathcal{H})$ is $d^2$ because there are $d$ diagonal
  coefficient and $\frac {d(d-1)} 2$ complex off-diagonal coefficient so $d +
  d(d-1)$ coefficient in total. The constraint $\Tr \rho = 1$ remove one degree
  of freedom, so we only have $d^2 -1$ dimension.
\end{proof}

\subsection{The case of the qubit}

In the case of a qubit, with $\dim \mathcal{H} = 2$ (complex dimension), we know
that the pure states, up to a phase shift can be represented on the Bloch sphere. We
would like to know how to represent mixed states. The dimension of
$\mathcal{D}(\mathcal{H})$ is 3, so we can hope for a simple representation. Any
density matrix from $\mathcal{H}$ can be written:
\[\rho = \frac12I + S\]

where $\Tr S = 0$. A base of the hyperplane of hermitian matrix of trace $0$ can
be given by Pauli matrices:
\[\sigma_Z = \mat{1&0\\0&1} \quad \quad \sigma_X = \mat{0&1\\1&0} \quad \quad
  \sigma_Y = \mat{0&-i\\i&0}\]

If we write $\bs\sigma = (\sigma_X,\sigma_Y,\sigma_Z)$, we can write
$\rho$ as:
\[\rho = \frac12 I + \bs r \cdot \bs \sigma\]

where $\bs r \in \R^3$ is usual 3D vector. We can check  However we have:

\begin{prop}
  $\rho \geq 0$ if and only if $\|\bs r\| \leq 1$
\end{prop}

\begin{proof}
  $\det \rho = 1 - \|r\|^2$
\end{proof}

We can then look at the purity $\gamma$ in function of $\bs r$. We have:

\begin{prop}
  $\gamma = \Tr(\rho^2) = \frac 12 (1 + \|\bs r\|^2)$
\end{prop}

\begin{cor}
  $\rho$ is pure if and only if $\|\bs r\| = 1$
\end{cor}

Mixed state are thus represented in Bloch ``ball''. The pure states are exactly
the one that are laying on the boundary i.e.\ on the sphere. One can check this
representation matches the usual Block sphere representation on pure states. The
uniform state is the center of the ball.

\subsection{Composite systems, Partial trace}

When must now ask how to model density matrix on multiple system. On pure state,
this is a simple tensor product $\ket{\Psi\Phi} = \ket \Psi \otimes \ket \Phi =
\ket \Psi\ket\Phi$. Luckily for us we have:
\[(\ket\Psi\ket\Phi) \otimes (\bra\Psi\bra\Phi) = \ket\Psi\bra\Psi \otimes \ket
  \Phi \bra \Phi\]

Where the $\otimes$ designate here the tensor product of operators and matrices.
We still have the same property of entanglement, i.e a state is entangled iff
the density matrix cannot be written as a tensor product.

What is interesting now is to study the statistical result of measurement in a
single one of the two quantum sub systems $\mathcal{H}_1$ and $\mathcal{H}_2$.
If we take an observable $A$ on $\mathcal{H}_1$ and its extension to
$\mathcal{H} = \mathcal{H}_1 \otimes \mathcal{H}_2$ which is $\tilde A = A
\otimes I$. If we have a density matrix $\rho = \rho_1 \otimes \rho_2$, then the
average of $A$ is $\Tr(\rho \tilde A) = \Tr(\rho_1A)\Tr(\rho_2) = \Tr(\rho_1A)$.
On a tensor product density matrix, the evaluation of $\tilde A$, only depend on
the part of $\rho$ in $\mathcal{H}_1$ and we would like to express that on any
density matrix. In order to do that, we rewrite our computation as
$\Tr(\rho\tilde A) = \Tr((\rho_1\Tr(\rho_2))A)$, we can then see that
$\rho_1\Tr(\rho_2)$ is the part of $\rho$ in $\mathcal{H}_1$.

\begin{defn}
  Given a tensor product $\mathcal{H} = \mathcal{H}_1 \otimes \mathcal{H}_2$,
  The \emph{partial trace over $\mathcal{H}_2$}, is an linear operator
  $\Tr_{\mathcal{H}_2} : \mathcal{L}(\mathcal{H}) \to
  \mathcal{L}(\mathcal{H}_1)$ defined on tensor product by:
  \[\Tr_{\mathcal{H}_2}(\rho_1\otimes \rho_2) = \rho_1 \Tr(\rho_2)\]
  and extended by linearity on the full $\mathcal{L}(\mathcal{H})$.
\end{defn}

\begin{prop}
  For any operator $\rho \in \mathcal{L}(\mathcal{H})$, and any observable
  $A\in\mathcal{O}(\mathcal{H}_1)$, we have:
  \[\Tr(\rho(A \otimes I)) = \Tr(\Tr_{\mathcal{H}_2}(\rho)A)\]
\end{prop}

\begin{proof}
  It's true if $\rho$ is a tensor product and so it is true on any $\rho$ by linearity.
\end{proof}

An important remark to be made is that if a pure state in entangled, its partial
trace will be mixed states. That is because, if we forgot the other space, Our
space will behave as a statistical mixture and not a quantum superposition
because depending of what the other state becomes, we can have any different phase.
For example if we have two qubits, and we have a
bell state $\ket \psi = \frac{\ket{00} + \ket{11}}{\sqrt 2}$, then
\[\Tr_2\big(\ket \Psi \bra \Psi\big) = \frac 12I\]


\section{Quantum operations}

Even if a closed quantum system has a unitary evolution, in real life, quantum
system are open, The undergo interaction with their environment whether it is
from external measurement or simply thermal relaxation. The goal of this section
is to build a representation of acceptable transformation for open systems in a
similar way that we say that any transformation of a closed system is unitary.

\subsection{Classical measurement}

The first and simplest example of external interaction in quantum theory is
measurement. When a quantum system interact with a macroscopic measurement
device, it is measured and collapse in a specific state. The usual framework for
measurement is projective measurement. It is
made by measuring a observable that fully describes the measurement
process.

Let $A \in \mathcal{O}(\mathcal{H})$ be an observable on $\mathcal{H}$. The
spectral decomposition of $A$ tells us that $A = \sum_a a P_a$, where the $a$
are the eigenvalues of $A$ and the $P_a$ orthogonal projector on the
corresponding eigenvector spaces. When starting in state $\ket \Psi$, We
measure $a$ with probability $\bra \Psi P_a \ket \Psi$, and we get we get
the output state:
\[ \frac{P_a \ket \Psi}{\sqrt{\bra \Psi P_a \ket \Psi}}\]

In fact $P_a$ is also a quantum measurement operator which detect if we measure
$a$ or not, and thus its average value is the probability of measuring $A$. We
can then express the same thing in the world of density matrices. When starting in
$\rho$, we expect $a$ with probability $\Tr(\rho P_a)$ and get as an output
state:
\[ \frac{P_a \rho P_a}{\Tr(\rho P_a)}\]

A important question when dealing with probability is whether they always sum to
one, and in this case, this is answered by the closure relation
\[\sum_a P_a = I\]

and as $\bra \Psi I \ket \Psi = \Tr(\rho I) = 1$, the probabilities are normalized

\subsection{Generalized measurement}

However in some case, quantum detector can perform other kinds of measurement.
In particular measurement that completely destroy the object instead of
projecting is in a specific vector space. The main example is a photon counting
detector. When a cavity is in a fock state $\ket n$, and we insert a photon
counting detector, the photons ``crash'' into the detector and are counted to be
$n$. The remaining state is always $\ket 0$, as there are no photons left. This
measurement is obviously non projective as $\ket 0$ is orthogonal to any $\ket
n$. We thus need a framework to handle this kind of measurement.

While a projective measurement of operator $N$, would have left the state in
state $\ket n$ because we applied $P_n = \ket n \bra n$.
The operation the detector apply to the system when measuring $n$ is $M_n = \ket
0 \bra n$. If we apply it to any state $\ket \Psi$, We have to normalize $M_n
\ket \Psi$. The squared norm is $\bra \Psi M_n^\dagger M_n \ket \Psi$ and by
analogy, this looks like our probability. However any group of $M_n$ cannot
represent a generalized measurement. We need a normalization condition which is
quite simple given the probability expression: $\sum M_n^\dagger M_n = I$.

\begin{defn}
  On a quantum Hilbert space $\mathcal{H}$, a \emph{generalized measurement} is a set
  of outcomes $o$ of the measurement (There can be more outcomes that the
  dimension of $\mathcal{H}$), and for each of them a measurement
  operator $M_o$. For the measurement to be complete, we require the
  normalization condition:
  \[\sum_o M_o^\dagger M_o = I\]

  In that case the probability of outcome $o$ in state $\ket \Psi$ is $\bra \Psi
  M_o^\dagger M_o \ket \Psi$ and the resulting state is:
\[\frac{M_o \ket \Psi}{\sqrt{\bra \Psi M_o^\dagger M_o \ket \Psi}}\]
\end{defn}

\begin{rem}
  A projective measurement is just a special case of generalized measurement
  with $M_o=P_o$ as $P_o^\dagger P_o = P_o$.
\end{rem}

\begin{prop}
  If we have a mixed state $\rho$, the action of this generalized measurement is
  to measure $o$ with probability, $\Tr(M_o\rho M_o^\dagger)$. The outcome would
  then be:
  \[\frac{M_o\rho M_o^\dagger}{\Tr(M_o\rho M_o^\dagger)}\]
\end{prop}

The question that is important now, is what happens when we forget the value of
the measurement. We can have each outcome $o$ with the corresponding
probability, so the resulting state is:
\[\rho_f = \sum_o \Tr(M_o\rho M_o^\dagger)\frac{M_o\rho M_o^\dagger}{\Tr(M_o\rho
    M_o^\dagger)}
  =\sum_o M_o\rho M_o^\dagger \]



\subsection{Quantum operations}

The goal of this section is to describe a formalism to express the evolution of
an open quantum system in term of density operators. Another order of presention
with deeper analysis can be found in (\TODO{} cite the book).

For sake of generality, The input state
$\mathcal{H}_i$ and the output system $\mathcal{H}_o$ will not be the same. In
most case, they will, but in some case the system we study is causally related to
an input system but is not the same.
What we want is an operator $\mathbb{E} : \mathcal{D}(\mathcal{H}_i) \to
\mathcal{D}(\mathcal{H}_o)$. That map the input mixed state to the output mixed
state and represent the evolution.

First, we remark that if $\rho$ is mixed state representing $\rho_1$ with
probability $p_1$ and $\rho_2$ with probability $p_2$, then the output state
must be $\mathbb E(\rho_1)$ with probability $p_1$ and $\mathbb E(\rho_2)$ with
probability $p_2$. Therefore in the general case we have :
\[\mathbb E(\sum p_i \rho_i) = \sum p_i \mathbb E(\rho_i)\]

$\mathbb E$ thus preserves convex combinations. A better way of representing
that is to say that $\mathbb E \in
\mathcal{L}(\mathcal{O}(\mathcal{H}_i),\mathcal{O}(\mathcal{H}_o))$ i.e.
$\mathcal{E}$ is linear on Hermitian operators. Any operator that preserves
convex combinations on $\mathcal{D}(\mathcal{H})$ can be extended to a linear
operator on Hermitian matrices (The proof is easy and not interesting). The
opposite is true if the operator preserves the positiveness and the value of the
trace.

However to be sure to keep positiveness in all case, when we have two maps on
different systems, we must have $\mathbb{E}_1
\otimes \mathbb{E}_2$, to also preserves positiveness. We now have all
conditions for a good definition.

\begin{defn}[Trace-preserving quantum operation]\label{def:tpqo}
  Given an input space $\mathcal{H}_i$ and an output space $\mathcal{H}_o$, a
  linear map $\mathbb E : \mathcal{O}(\mathcal{H}_i) \to
  \mathcal{O}(\mathcal{H}_o)$ is said to be a \emph{trace preserving quantum
    operation} (or quantum map) if:
  \begin{itemize}
  \item It preserves trace i.e $\Tr = \Tr \circ\; \mathbb E$.
  \item It is completely positive i.e, for any other space $\mathcal{H}_0$ with
    identity quantum operation $\mathbb I_0$, The map $\mathbb I_0 \otimes
    \mathbb E : \mathcal{O}(\mathcal{H}_0 \otimes \mathcal{H}_i) \to
    \mathcal{O}(\mathcal{H}_0 \otimes \mathcal{H}_o)$ preserves the positiveness
    of Hermitian operators.
  \end{itemize}
\end{defn}

This definition is nice and clean, but not very easy to manipulate, so we'll
need more efficient representation to be able to manipulate them on computers.
We will see that in \cref{ssec:kraus}. Afterwards, in \cref{ssec:interp}, we'll see
why this formalism can represent all sorts of open quantum evolutions, by giving
a more precise existence to the environment.

\subsection{Non-trace preserving quantum operations}

Restraining ourselves to an operator preserving the trace can be a problem for
some kinds of evolution. For example, if we look at a generalized measurement
${(M_o)}_o$, The operation of measuring and forgetting is
\[\mathbb{M}(\rho) = \sum_o M_o \rho M_o^\dagger\]

However, when we remember the outcome $o$, the operation is $\rho \mapsto
\frac{M_o \rho M_o^\dagger}{\Tr(M_0\rho M_0^\dagger)}$ which is \emph{not}
linear. The associated linear operation is $\mathbb{M}_o(\rho) = M_o\rho
M_0^\dagger$ which satisfies all properties of \cref{def:tpqo} except preserving
the trace. In fact $\mathbb{M}_o$ describes a process that is not sure to
happen. The probability that $\mathbb{M}_o$ happens when we do the measurement
on $\rho$ is $p_o = \Tr(\mathbb{M}_o(\rho))$ and the resulting density matrix is
$\mathbb{M}_o(\rho)/p_o$.
Non-trace preserving quantum operation therefore represent
operations where the observer has learnt some information on the system. Notice
that here, the notion of observer is a mix of the notion of drawing a value from
the probability measure that the density matrix represents and the usual observer
associated to quantum collapsing. Therefore the generic definition for quantum
operators is:
\begin{defn}[quantum operation]\label{def:qo}
  Given an input space $\mathcal{H}_i$ and an output space $\mathcal{H}_o$, a
  linear map $\mathbb E : \mathcal{O}(\mathcal{H}_i) \to
  \mathcal{O}(\mathcal{H}_o)$ is said to be a \emph{quantum
    operation} (or quantum map) if:
  \begin{itemize}
  \item It decreases the trace i.e $\Tr \circ\; \mathbb E < \Tr$.
  \item It is completely positive i.e, for any other space $\mathcal{H}_0$ with
    identity quantum operation $\mathbb I_0$, The map $\mathbb I_0 \otimes
    \mathbb E : \mathcal{O}(\mathcal{H}_0 \otimes \mathcal{H}_i) \to
    \mathcal{O}(\mathcal{H}_0 \otimes \mathcal{H}_o)$ preserves the positiveness
    of Hermitian operators.
  \end{itemize}
\end{defn}

Trace preserving operation represent deterministic processes
that do not leak any information the observer whereas non trace preserving operations describe
processes that may happen with some probability (the trace of the output) and for which the
observer has learnt some classical information on the system. A \emph{complete system of
  quantum operation} (or \emph{measurement model}) ${(\mathbb{M}_o)}_o$ is a set of quantum
operation such that $\sum_o \mathbb M_o$ is trace preserving. We can evaluate
this system like a generalized measurement, The probability of the outcome $o$
is $\Tr(\mathbb M_o(\rho))$ and the output state is:

\newcommand{\trnorm}[1]{\frac{#1}{\Tr\left({#1}\right)}}

\[\trnorm{\mathbb M_o(\rho)}\]

We can now look at two complete system in sequence to get the following
property.

\begin{prop}\label{prop:qocomp}
  Given $(\mathbb M_o)$ and $(\mathbb K)_i$ two measurement models, The
  probability or measuring $o$ then $i$ in state $\rho$
  is $\Tr(\mathbb K_i (\mathbb M_o(\rho)))$ and the output state is:
  \[\trnorm{\mathbb K_i (\mathbb M_o(\rho)))}\]
\end{prop}

\begin{proof}
  \TODO{}
\end{proof}

This obviously works for more than two systems and that's why we can compose
partial operator without renormalizing each time and only care about
renormalizing at the end. The behavior is exactly the same as if we had a single
system of operator indexed on $(o,i)$ where $\mathbb E_{o,i} = \mathbb K_i \circ
\mathbb M_o$.

\subsection{Krauss operators, Krauss Maps}\label{ssec:kraus}

Until we have only manipulated abstract definition for quantum operation, let's
see how to represent them numerically. In fact we already know a numerical
formula for a certain kind of operation: unread generalized measurement. The
form we know is $\mathbb{M}(\rho) = \sum \mathbb M_o(\rho) = \sum M_o\rho
M_o^\dagger$. In fact we can prove this form is general and is called
\emph{Krauss decomposition} or \emph{Krass map}.

\begin{thm}[Krauss]
  Given a application $\mathbb E : \mathcal{O}(\mathcal{H}_i) \to
  \mathcal{O}(\mathcal{H}_o)$ is a quantum operation if and only if there exist
  a set of operators $E_i \in \mathcal{L}(\mathcal{H}_i, \mathcal{H}_o)$ such
  that $\sum E_i E_i^\dagger \le I$ and:
  \[\mathbb E(\rho) = \sum_i E_i\rho E_i^\dagger\]
\end{thm}

\begin{prop}
  The operation is trace preserving if and only if
\[\sum_i E_i E_i^\dagger = I\]
\end{prop}

\begin{proof}
  \TODO{}
\end{proof}

\begin{proof}[Proof of the theorem]
  \TODO{}
\end{proof}

Any trace preserving quantum operators can thus be expressed as an unread
quantum measurement. It is like if all the decoherence processes were due to unread
measurements from the environment. We'll see that in details in next section

\subsection{Interpretation with environment}\label{ssec:interp}

\TODO{}

\section{Likelihood in terms of quantum maps}

The experiment can be represented as a starting average state $\rho$ that we
want to determine with tomography. This state evolve according to the
experimental setup and thanks to some measurements made by the experimenter. For
a given run of the experiment, the result are $y_1,\ldots,y_m$.
The state $\rho_i$ will be the state just after the measurement $i$. The
evolution from $\rho_{i-1}$ to $\rho_i$ is given by a quantum operation that
depends on the result of the measurement:

\[\rho_i = \trnorm{\mathbb K_{i,y_i}(\rho_{i-1})}\]

The system of $\mathbb K_{i,y_i}$ is complete for a given $i$. According to
\cref{prop:qocomp}, The probability of getting the results $y_1, \ldots, y_n$ is
\[P(y_,,\ldots, y_n) = \Tr(\mathbb K_{m,y_m} \circ \ldots \circ \mathbb K_{1,y_1}(\rho))\]

We can then use the adjoint maps for the Frobenius product (defined by $\Tr(A\mathbb K(B)) = \Tr(\mathbb
K^*(A)B))$ and get
\[P(y_,,\ldots, y_n) = \Tr(\rho \mathbb K_{1,y_1}^* \circ \ldots \circ \mathbb
  K_{m,y_m}^*(I)) = \Tr(\rho E_{y_1,\ldots, y_n})\]

The matrix $E$ is called the \emph{effect matrix} of the measurement
$y_1,\ldots,y_n$.

\begin{prop}
  The adjoint of a quantum operation is completely positive so all the $E_i$ are
  positive hermitian matrices.
\end{prop}

\begin{proof}
  \TODO{}
\end{proof}


If we have $n$ sequence of measurement, We'll have the effect
matrices $E_1, \ldots, E_n$, that represent each measurement. The log-likelihood
function is thus

\begin{equation}\label{eqn:ll}
  \ell(\rho) = \sum_i \log (\Tr(\rho E_i))
\end{equation}

We just need to be able to compute the $\mathbb K_{i,y_i}$, and we'll do that in
the next section. To compute the adjoint, we simply use the representation as
Krauss operators Indeed if $\mathbb K(\rho) = \sum\limits_o M_o\rho M_o^\delta$
then:

\[\mathbb K^*(\rho) = \sum_o M_o^\dagger \rho M_o\]

\section{Computation of Krauss operators for QND measurement}

Mostly from~\cite{VM19} but with a bit of~\cite{Har06}

\TODO{}

\chapter{Convex optimization}

Now we need to find the maximum $\rho\ml$ of $\ell$, given that $\rho\ml$ is in
$\mathcal{D}$, the set of density matrix. The problem we want to solve is
\[\maxim {\ell(\rho)} \rho {\rho \in \mathcal{D}}\]

This problem is ``easy'' because it is convex and as we'll see, convex problem
have fast solution.

\section{Reminders on convex optimization}

We must now define what is a convex problem, I assume the readers know what is a
convex set. We must now define convex cones. This presentation is based on \TODO{}

\subsection{Convex cones}

\begin{defn}
  A set $K \subset E$ where $E$ is a vector space on $\R$ is a \emph{cone} if
  \[\forall x \in K.\, \forall \lambda \in \R_+, \lambda.x  \in K\]
  The $\lambda$ can be 0 in this definition i.e we must have $0 \in K$.
\end{defn}

A convex cone is simple a cone that is convex. We are particularly interested in
proper cones:

\begin{defn}
  A cone $K \subset E$ is a \emph{proper cone} if
  \begin{itemize}
    \item It is closed ($K = \overline K$)
    \item Is is solid ($ \mathring K \neq \emptyset$)
    \item Is is pointed (It contains no lines)
  \end{itemize}
\end{defn}

In particular the set of vector with non negative coordinate (the positive orthant) or the set of
positive hermitian matrices ($\mathcal{O}_+(\mathcal{H})$) are proper cones. With those cone we can define a
generalized inequality:

\begin{defn}
  Two vector $a$ and $b$ are said to be \emph{inferior according to $K$} which is denoted by $a
  \leq_K b$ if $b - a \in K$. We say that $a <_K b$ if $b - a \in \mathring K$
\end{defn}

In particular, the usual componentwise inequality on vectors is the the
inequality of the positive orthant and the usual inequality on matrices is the
inequality of $\mathcal{O}_+(\mathcal{H})$.

The last concept we need is the one of duals cones:

\begin{defn}
  The \emph{dual cone} $K^*$ of a cone $K \subset$ where $E$ is euclidean or hermitian is the set
  \[ K^* = \{y \in \R^n,\; \forall x \in K,\, \braket y x \geq 0\}\]

  In the hermitian case, the $\geq 0$ mean real and non negative.
\end{defn}

A cone is self dual if it is its own dual. In the literature, the hermitian case
is sometimes called \emph{internal dual cone}

\begin{prop}
  The dual of a proper cone is a proper cone
\end{prop}

\begin{proof}
  \TODO{}
\end{proof}

\begin{prop}
  The cone of positive hermitian matrices is self dual
\end{prop}

\begin{proof}
  If $H$ is hermitian and $\langle H | A \rangle \geq 0$ for all $A \in
  \mathcal{O}_+(\mathcal{H})$, Then if we diagonalize $H$, If there is any
  negative eigen value, the matrice which has as diagonal one in front of that
  eigenvalue and 0 in front of other will make the Frobenius product negative
  which is impossible, thus $H \geq 0$.

  For a general matrice $M$, we have the Cartesian decomposition $M = A + iB$
  with $A$ and $B$ hermitian. The fact that the Frobenius product is always real positive is

\end{proof}


\subsection{Convex problems}

I suppose that the reader knows the usual definition of a convex function,
however, this can be generalized to proper cone equality:

\begin{defn}
  A function $f : \dom f \subset E \to F$ where $E$ and $F$ are real vector
  space is said to be $K$-convex for $K$ a proper cone of $F$ if $\dom f$ is
  convex and
  \[\forall \lambda \in [0,1],\, \forall x,y \in \dom f, \lambda f(x) + (1 -
    \lambda)f(y) \geq_K f(\lambda x + (1-\lambda)y)\]
\end{defn}

If $K = \R_+$, this is the usual convexity. A convex problem is then a problem
of the form
\begin{equation}\label{eqn:stdprb}
\minima{f_0(x)}{x \in \R^n}{f_i(x) &\leq_{K_i} \\ \!\!h_j(x) &= 0}
\end{equation}
where $f_0$ is convex, each $f_i : \R^n \to E_i$ is $K_i$-convex for $i = 1,\ldots,m$ and each
$h_j : \R^n \to \R$ are affine for $j = 1,\ldots,p$. Obviously, the domain isn't really $\R^n$
but $\bigcap_i \dom f_i$. However as all convex
functions can be extended setting their values to $\infty$ outside their domain,
so the distinction isn't really relevant (affine functions are always defined
everywhere).

\begin{defn}
  A point $x$ is said to be \emph{feasible} if it satisfies all the constraint
  in the ``subject to''.
\end{defn}

The various convexity constraints ensure that

\begin{prop}
  The set of feasible points is convex.
\end{prop}

The \emph{optimum} value of the problem is the minimal value reached or approached by $f_0$ it
is noted $f_{opt}$ in the rest of this section. In the approached case, it is the
infimum of all the value taken by $f_0$ on the set of feasible points.
Any $x$ that reaches $f_{opt}$ is called a \emph{solution point}.

\begin{prop}
  The set of solution point is always convex (but may be empty).
\end{prop}

We can also express maximization problems : the concave case of the problem is
our case of problem in the log-likelihood estimation.
\[\maxima{f_0(x)}{x \in \R^n}{f_i(x) &\geq_{K_i}\\\!h_j(x)&=0}\]

Where $f_0$ is concave, each $f_i$ is $K_i$-concave and each $h_j$ is affine.

\subsection{Strong convexity}

\begin{defn}
  A function, $f : \R^n \to \R$ is strongly convex on a set $A$, if is $\class
  2$ on $A$ and if there is a constant $\mu$ such that
  for any point of $A$, we have
  \[\dparn f x 2 \geq \mu.I\]
  where $\dparn f x 2$ is the hessian matrix of $f$.
\end{defn}

A problem is strongly convex if $f_0$ is strongly convex on the feasible set
which is closed (This happens if all constraints function are continuous for example).

\begin{prop}
  A strongly convex problem has exactly one solution that is reached in a single point
  \[f_{opt} = f(x_{opt})\]
\end{prop}

\subsection{Dual problem}

A dual problem for a given problem is like the problem viewed from the other
side. If our main (primal) problem is a minimization, the goal of the dual
problem is to produce the best possible lower bound. The dual will thus be a
maximization problem. In order to do that, we first
need to define the Lagrangian of the problem (which has nothing to do with the
Lagrangian of classical mechanics).

\begin{defn}
  Given a problem in form~\ref{eqn:stdprb}, We define its \emph{lagrangian} by
  the function
  \[ L:\begin{aligned}[t] \R^n \times \prod E_i \times \R^p \;&\to\; \R\\
      (x,\eta_1,\ldots,\eta_m,\lambda_1,\ldots,\lambda_p) \;&\mapsto\; f_0(x) +
      \sum_{i = 1}^m \braket {\eta_i}{f_i(x)} + \sum_{j = 1}^p \lambda_j h_j(x)
    \end{aligned}
  \]
\end{defn}


In order for it to be under the minimum of the primal independently of $x$ when the constraints are
satisfied, we need to minimize on $x$

\begin{defn}
  The \emph{Lagrange dual function} or simply \emph{dual function} is defined by:
  \[g(\eta,\lambda) = \inf_{x \in \R^n} L(x,\eta,\lambda)\]
\end{defn}

\begin{prop}
  $g$ is concave.
\end{prop}

\begin{proof}
  \TODO{}
\end{proof}

We can now reach our goal to have a lower bound independent of $x$:

\begin{prop}
  If $\forall i \in \{1,\ldots,n\}, \eta_i \geq_{K_i^*} 0$, and the optimum of the primal is
  $f_{opt}$, then
  \[g(\eta,\lambda) \leq f_{opt}\]
\end{prop}

\begin{proof}
  Let's take $x$ any value respecting the constraints. We have
  \[g(\eta,\lambda) \le L(x,\eta,\lambda) \le f_0(x)\]
  The first inequality comes from minimization over all possible $x$.
  The second inequality comes from the fact that $f_i(x) \leq_{K_i} 0$ and
  $\eta_i \geq_{K_i^*} 0$ so, by definition of the dual cone, $\braket
  {\eta_i}{f_i(x)} \leq 0$. Furthermore all $h_j(x) = 0$. If we minimize over
  all $x$, we get the property.
\end{proof}

If we want to find the best lower bound, we thus have the following convex
problem to solve which is called the \emph{dual problem}
\begin{equation}\label{eqn:dual}
\maxim{g(\eta,\lambda)}{\eta,\lambda}{\eta_i \geq_{K_i^*} 0}
\end{equation}

\subsection{Strong duality and KKT conditions}

Here we study the link between the dual and the primal problem and try to find
conditions for solutions and various other properties. Suppose we have a problem in
standard form~\ref{eqn:stdprb} with its optimum $\tilde f$ and it's canonical
dual~\ref{eqn:dual} with its optimum $\tilde g$. What we have proven in the
previous section is that
\[\tilde g \leq \tilde f\]

This is called \emph{weak duality}. In some specific cases, we have $\tilde g =
\tilde f$, this is called \emph{strong duality}. The fact that a problem is
strongly dual is very important for it's study and impact various properties.
One way of proving that a convex problem is strongly dual is:
\begin {prop}[Slaters' constraint qualification]\label{prop:slater}
  If the primal convex problem has an internal feasible point, i.e a point that is in
  the interior of the set of feasible points, that is a point $x$ that satisfies
  $f_i(x) <_{K_i} 0$ and $h_j(x) = 0$, then the problem is strongly dual.
\end{prop}

\begin{proof}
  \TODO{}
\end{proof}

\begin{prop}[Complementary slackness]
If strong duality holds and $\tilde x$ is optimal for the primal and $\tilde
\eta, \tilde{\lambda}$ are optimal for the dual, then:
\[g(\tilde \eta, \tilde{\lambda}) = L(\tilde x, \tilde{\eta},\tilde{\lambda}) = f(\tilde{x})\]
and thus $\braket {\tilde\eta_i}{f_i(\tilde{x})} = 0$ for any $i$.
\end{prop}

\begin{proof}
  \[ f(\tilde x) = g(\tilde \eta, \tilde{\lambda}) \leq
    L(\tilde x, \tilde{\eta},\tilde{\lambda}) \leq f(\tilde{x})\]
\end{proof}

\begin{thm}[KKT conditions]\label{thm:KKT}
  The Karush-Kuhn-Tucker conditions, given $x,\eta,\lambda$ are:
  \begin{itemize}
  \item $x$ is feasible
  \item For all $i$, $\eta_i \geq_{K_i^*}0$
  \item For all $i$, $\braket {\eta_i}{f_i({x})} = 0$
  \item The gradient of the Lagrangian $\dpar L x$ is 0:
    \[ \nabla f_0(x) + \sum_{i = 1}^m \nabla\braket{\eta_i}{f_i(x)} +
      \sum_{j=1}^p \lambda_j \nabla h_j(x) = 0\]
  \end{itemize}
  for a strongly dual convex problem, There are equivalent to the optimality of
  $x$ for the primal and the optimality of $\eta,\lambda$ for the dual.

\end{thm}

\begin{proof}
\TODO{}
\end{proof}

\begin{prop}\label{prop:slaterKKT}
  If we have Slater's condition (\ref{prop:slater}), $x$ is optimal if and only if there exists a
  $\eta,\lambda$ satisfying the KKT conditions.
\end{prop}

\begin{proof}
\TODO{}
\end{proof}

\section{Solution characterization}

\subsection{Characterization}

We now want to study the optimal solutions of the maximum likelihood problem:
\[\maximf{\ell(\rho)}{\rho \in \mathcal{D}(\mathcal{H})} \]

which literally means, ``maximize the log-likelihood on density matrices''. In
standard form, this is:

\[\maxima{\displaystyle\sum_i \log(\Tr(\rho E_i))}{\rho \in \mathcal{O}(\mathcal{H})}
  {\rho &\geq 0\\\Tr \rho &= 1}
\]

The optimization is on the vector space $\mathcal{O}(\mathcal{H})$. This problem
satisfies Slater's condition (\ref{prop:slater}) as the identity matrix is alway
in the interior of $\mathcal{D}$. Therefore all results for previous section are
available, in particular we can characterize the solution using the KKT
conditions (\ref{thm:KKT}). In particular:

\begin{prop}
  $\rho\ml$ is an optimal solution if and only if there
exists $\eta \ge 0$ and $\lambda$ such that
\[\braket \eta {\rho\ml} = 0 \quad \text{and} \quad \nabla \ell + \eta +
  \lambda I = 0\]
\end{prop}

\begin{proof}
  Using \cref{prop:slaterKKT} and $\displaystyle\dpar{\braket \eta \rho}\rho = \eta$.
\end{proof}


We can also make the $\eta$ disappear from the condition:
\begin{prop}
  $\rho$ is an optimal solution if and only if $[\rho, \nabla \ell] = 0$ and
  there is a $\lambda$ such as $\lambda P \le \nabla f \le \lambda I$, where $P$
  is the orthogonal projector on the range of $\rho$.
\end{prop}

\begin{proof}
  \TODO{}
\end{proof}

\subsection{Unicity}

The simplest case for the solution to exist and be unique is for the problem do
be strongly convex:

\begin{prop}
  If $\Span_i(E_i) = \mathcal{O}(\mathcal{H})$, then the problem is strongly convex.
\end{prop}

\begin{proof}
The gradient of $\ell$ is:
\begin{equation}
\nabla \ell = \sum_i \frac{E_i}{\Tr(\rho E_i)}
\end{equation}

  \TODO{}
\end{proof}

However if $\Span(E_i)$ is not full, we still have some properties: exact
solutions will exist and for an affine sub-space of $\mathcal{D}$ orthogonal to
$\Span(E_i)$. Actually it will be exactly the orthogonal of $\Span(E_i)$
projected on $\mathcal{D}$. Which solution to choose among those was one of the problem that
was still unsolved when I arrived, I solve it up to personal taste in \cref{sec:fixspan}








\section{Projected gradient method}

In this section the goal is to actually compute a solution $\rho\ml$ to the
max-log-likelihood problem up to
numerical errors.

\subsection{Algorithm}

On unconstrained convex problem, the simplest way to find the optimum is to a
``gradient descent''. It means that when we go downward (toward lower $f_0$)
following the gradient. The algorithm start from $x = x_0$ and is:

\begin{itemize}
\item Compute $\nabla f_0(\rho)$.
\item Choose an $\varepsilon$
\item Move by $h = -\varepsilon \nabla f_0(x)$, i.e. $x \leftarrow x + h$.
\end{itemize}

\

\noindent The choice of $\varepsilon$ is complex and has important consequences.
Some examples are:
\begin{itemize}
\item Choose always the same value
\item Choose slowly decreasing value independent of the rest.
\item Choose the best value that minimize $t \mapsto f_0(x + t\nablaf_0(x))$.
\item Choose the best value that minimize the second order approximation
  \[t \mapsto f_0(x) + t\|\nabla f_c(x)\|^2 + \frac {t^2} 2 \nabla f_0^t \cdot
  \nabla^2\!f_0 \cdot \nabla f_0\]
\end{itemize}

In practice the last one was chosen.
\begin{prop}
  If $f_0$ is strongly convex,
  the gradient descent algorithm with second order approximation converges
  toward a solution for any unconstrained problem
\end{prop}

\begin{proof}
  \TODO{}
\end{proof}

However out problem is not unconstrained. The solution must in the feasible set
$\mathcal{D}$. One way of dealing with that is to project the new point $x + h$
back to $\mathcal{D}$. Projecting a point on a compact convex set is always
doable. We'll see how to it numerically in \cref{ssec:proj}

\begin{prop}
  For a constrained strongly convex problem, the projected gradient descent
  method with second order approximation converges
\end{prop}

\begin{proof}
  \TODO{}
\end{proof}

In practice we'll do ``gradient ascent'' as in our problem as we are maximizing a
concave function. The full algorithm is thus:

\begin{itemize}
\item Compute $\nabla f_0(\rho)$ and $\nabla^2 f_0(\rho)$
\item Choose an $\varepsilon$ that maximizes (can be done in $O(1)$ time):
  \[t \mapsto f_0(x) + t\|\nabla f_c(x)\|^2 + \frac {t^2} 2 \nabla f_0^t \cdot
  \nabla^2\!f_0 \cdot \nabla f_0\]
\item Move by $h = \varepsilon \nabla f_0(x)$.
\item Project on $\mathcal{D}$. $x \leftarrow P_\mathcal{D}(x+h)$.
\end{itemize}

\subsection{Projection}\label{ssec:proj}

For a given point $x \in \mathcal{O}(\mathcal{H})$, its projection on
$\mathcal{D}$ is the point of $\mathcal{D}$ that is the nearest from $x$. We
want to:
\[\minim{\|x - \rho\|}{\rho}{\rho \in \mathcal{D}}\]

Let first diagonalize $x \in \mathcal{O}(\mathcal{H})$ into $x = UDU^\dagger$.\\
We have $\|x - \rho\| = \|D - U^\dagger \rho U\|$ but we have
$U^\dagger \rho U \in \mathcal{D}\iff
\rho \in \mathcal{D}$, thus our problem is equivalent to:
\[\minim{\|D - \rho\|}{\rho}{\rho \in \mathcal{D}}\]

But any outdiagonal coefficient of $\rho$ would only increase the distance, as
we can remove all of them and stay in $\mathcal{D}$ (Removing only part of them
would guaranty to stay in $\mathcal{D}$). Our problem is thus equivalent to
(given that $D = diag(d)$):
\[\minima{\|d - x\|}{x \in\R^n}{ x&>0\\ \|x\|_1 &= 1}\]

This is therefore just projecting a point on a simplex of dimension $n-1$ in
$\R^n$, a much simpler problem but still not trivial.

\TODO{} Understand and explain (Julia)

\begin{verbatim}
function proj(p::Vector{Float64})
    p = copy(p);
    n = length(p);
    perm = sortperm(p);
    sump = -1.0;
    iout = 0;
    c=0.0;
    for i0 in n:-1:1
        sump += p[perm[i0]];
        c = sump/(n-i0+1);
        if(p[perm[i0-1]] < c < p[perm[i0]])
            iout = i0;
            break;
        end
    end
    p .= c;
    p[perm[1:iout-1]] .= 0;
    return p;
end

\end{verbatim}



\chapter{First Results}
\section{Extracting the results and basic error}

Mention the results already proven and put a plot of reconstructed state with
the errorbars we already had.

We get error on matrix value and photon number

\section{Maxwell Demon experiment}

% Here or first chapter
Mainly Luis notes and presentation


\section{Reminders on Quantum information}

Wikipédia

\subsection{Classical Information theory}

\subsection{Quantum information theory}

\section{Thermodynamical analysis}

Built the new second law from

Mainly the long notes from Luis


\section{Experimental results}

\paragraph{Combination of reconstructions} How we build the matrices
experimentally : from code

Plots and error bars ?

\paragraph{TODO} Need to save the data needed for the report

\chapter{Error estimation and validity proofs}
\section{Quick approach : Monte carlo estimation}
% Only on specific case of probability vectors
\subsection{Reminders on Markov chains}

Continuous Markov chain notes

\subsection{Truncated gaussian simulation}
% Convergence proofs : L O L !

\section{Probability distribution around maximum}

Full rank and partial rank case

Give the formula that we will prove by intuition

Will probably need the transition from the z hessian to the usual notation here.

\section{Complete first order error-bars}

Use \cite{SPRAL17} but generalise. Will try to compact the proofs

Maybe some stuff will go in the appendices
\subsection{Full rank}

\subsection{Low rank}

\section{Fix the non full span problem}\label{sec:fixspan}

\subsection{Centering}

Explain approach coefficient by coefficient

Prove the logarithmic barrier

\subsection{Two objective optimisation}

Compare approachs and prove them :
\begin{itemize}
  \item Projected gradient on argmax
  \item Central path method
\end{itemize}

\chapter{Final Results}

\section{Approximations and implementation}

Gradient of entropy, projections, ...

Relevant implementation details

Equations of covariance propagation. All first order error.

\section{Plots}

\paragraph{TODO} Gather data for plots

\section{Interpretation}

Well crafted bullshit

\chapter*{Conclusion} %and bibliography
\addcontentsline{toc}{chapter}{Conclusion - Thanks - Bibliography}

Conclusion



\vfill

\paragraph{\Huge Thanks}
% \addcontentsline{toc}{chapter}{Thanks}

\

\vspace{3mm}

\begin{itemize}

\item Thanks to Igor Dotsenko for welcoming me in his lab, showing me his
  experimental setup and giving me interesting things to do around it.
\item Pierre Rouchon
\item Valentin Metillon
\item Luis Najera

\end{itemize}

\vfill


% Bibliography

% \addcontentsline{toc}{chapter}{Bibliography}

\bibliographystyle{plain}

{\let\clearpage\relax \bibliography{report}}


\appendix

\chapter{Quantum mechanics pictures}\label{app:pict}

Picture are different way to perceive and express quantum mechanics. They vary
in how the system state and the various operator change over time. All those
representation yield the same mechanics and are equivalent up to certain change
of Hilbert space basis dependent on time. Going from one to the other is just up
to a unitary $U(t)$.

However, non-unitary evolution like decoherence or external measurement
cannot be moved like that because it is not inversible. Therefore such
evolutions will always apply to state.

\section{Schrodinger picture}

The Schrodinger picture is the usual representation of quantum mechanics. In
this context only the state of the system varies and the way to observe it do
not change. When the system evolves under Hamiltonian $H(t)$,
the various operators relevant to the system are constant (unless they vary
because of a external source which is not the system) and the
state follow the Schrodinger equation:
\begin{eqn}\label{eqn:schro}
\[i\hbar \frac{\partial \ket \Psi}{\partial t} (t) = H(t) \ket {\Psi(t)} \]
\end{eqn}

\begin{prop}
  If $H$ is constant over time, the solution of~\cref{eqn:schro} is:
  \[ \ket {\Psi(t)} = e^{-i\frac H\hbar t}\ket{\Psi(0)}\]
\end{prop}

On very important theorem that makes a link the Heisenberg picture is the
following:

\begin{thm}[Ehrenfest]\label{thm:ehren}
  \[\der{}t\langle A\rangle = \frac i\hbar\langle[H,A]\rangle + \left\langle\dpar
      A t \right\rangle\]
\end{thm}

\begin{proof}
  \TODO
\end{proof}


\section{Heisenberg picture}

In the Heisenberg picture however, the state in $\mathcal{H}$, only correspond
to the initial state and represent the whole trajectory. However to measure an
observable a time $t$, you its expression $A(t)$ at this point in time. The
equation that rules this evolution is



\begin{eqn}
  \[\der At   = \frac i {\hbar}[H,A] + {\left(\dpar At \right)}_{\!\!H}\]
\end{eqn}

Here the $[\cdot,\cdot]$ is the commutator and the partial derivative is the
variation of $A$ due to external element out of the system (i.e.~the variation
of H in Schrodinger picture). This equation is actually the not-averaged version
of Ehrenfest theorem (\ref{thm:ehren})

\begin{prop}
  The Schrodinger picture and Heisenberg picture describe the same mechanics. In
  particular $\bra \Psi A \ket \Psi$ is the same for any operator in both pictures.
\end{prop}

\begin{proof}
  The value of the average in Schrodinger picture if given by Ehrenfest theorem.
  Let's compute the same average in Heisenberg picture. On the right side, the
  averaging give instantly the right hand of Ehrenfest theorem. We only have
  left to prove:
  \[ \left \langle \der A t\right\rangle = \der{}t\langle A\rangle\]
  But this is still true by linearity.
\end{proof}

In fact, The Schrodinger equation has general which is the unitary evolution
operator $U(t)$. From there, the evolution of the state in Schrodinger's picture
in $\ket {\Psi(t)} = U(t) \ket {\Psi(0)}$, whereas the evolution of a operator
in Heisenberg picture is $A(t) = U^\dagger(t)A_0(t)U(t)$, where $A_0(t)$
expresses the variation from external elements.

If the Hamiltonian is time-independent, $U(t) = e^{-i\frac H\hbar t}$

\section{Interaction picture}

Sometimes, in order to compare two phenomenon, it is useful to compare two
Hamiltonian in certain way. Usually, this is to compare the free evolution of a
system to the interaction with another system, this is why this is called the
interaction picture. Will split our Hamiltonian in two parts:
\[H = H_0 + H_1\]
In most case we'll try to keep $H_0$ time independent and simple, whereas $H_1$
will contain all the complexity of the system. That way, $U_0(t)$, will still be
$e^{-i\frac {H_0}\hbar t}$. We'll then make operator evolve with $H_0$, when
state evolves with $H_1$. The equations are:

\[i\hbar \frac{\partial \ket \Psi}{\partial t} (t) = H_1(t) \ket {\Psi(t)} \]
\[A(t) = U_0^\dagger(t)A_0(t)U_0(t)\]

This equivalent to manipulating state in a moving frame that moves according to
$U_0$. The Schrodinger frame would then be the fixed frame and the Heisenberg frame
would be the one that move exactly with the state.

\chapter{Covariance}\label{app:cov}

\section{Covariance and variance}

\begin{defn}
  Given two random vector $X \in \R^n$ and $Y \in \R^m$, we let the covariance
  matrix be defined by:
  \[\cov(X,Y) = {\big(\cov(X_i,Y_j)\big)}_{i \leq n, j \leq m}\]
\end{defn}

The fundamental goal of the covariance matrix is to have $\bra a \cov(x,y) \ket
b = \cov(a \cdot x, b \cdot y)$
\begin{prop} If $X \in \R^n$ and $Y \in \R^m$ are two random vectors, we have $\cov(X,Y) = {\cov(Y,X)}^t$.
\end{prop}
\begin{prop} If $A$ is a deterministic matrix, we have $ \cov(A X, Y) = A \cov(X,Y)$
\end{prop}

\begin{defn}
  Given a random vector $X \in \R^n$, We define its variance by
  \[V(X) = \cov(X,X)\]
\end{defn}

\begin{prop} For $X \in \R^n$a random vector, we have $V(X) > 0$
\end{prop}

\section{Correlation}\label{sec:correl}

\begin{defn}
  If $X$ and $Y$ are two real valued variable that are not fixed (non-zero
  variance), we have:
  \[\rho = \left|\frac {\cov(X,Y)}{\sigma(X),\sigma(Y)}\right|\]
  where $\sigma(X) = \sqrt{V(X)}$
\end{defn}

\begin{prop}\label{prop:correl1}
  We always have: $|\rho| \le 1$
\end{prop}

We can extend the correlation to the multivariate case by setting
\[\rho = {V(X)}^{-\frac12}\cov(X,Y){V(Y)}^{-\frac12}\]
The norm of $\rho$ now becomes the symmetric part of the polar decomposition:  $|\rho|
= {(\rho\rho^t)}^{\frac12}$. We can now get the theorem that give the bound on the
correlation:

\begin{thm}\label{thm:correln}
  If $X \in \R^n$ and $Y \in \R^m$ are random vectors, and $V(Y)$ is invertible,
  we have:
  \[\cov(X,Y){V(Y)}^{-1}\cov(Y,X) \leq V(X)\]
\end{thm}

\begin{cor}
  If $V(X)$ is also invertible, we have $|\rho| < I$
\end{cor}

\begin{proof}
  We take $a \in R^n$ such that $\bra a V(X) \ket a > 0$ and any $b \in \R^m$.
  By using~\cref{prop:correl1}, we get:
  \[ \frac{ \bra a \cov(X,Y) \ket b}{\sqrt{\bra a V(X) \ket a}\sqrt{\bra b V(Y)
        \ket b}} \leq 1\]
  To saturate the inequality, we can maximize the numerator on $b$, but keep the
  denominator constant. If we use the Lagrange multiplier method, we want to
  find a critical point of:
  \[\mathcal{L}(b,\lambda) = \bra a \cov(X,Y) \ket b + \lambda \bra b V(Y) \ket
    b\]

  We thus need to have:
  \[ \bra a \cov(X,Y) + 2\lambda\bra b V(Y) = 0\]
  and thus:
  \[ \bra b = - \frac 1 {2\lambda} \bra a \cov(X,Y) {V(Y)}^{-1}\]
  By substituting in the first equation we get:
  \[ \frac{ \bra a \cov(X,Y) {V(Y)}^{-1} \cov(Y,X) \ket a}
    {\sqrt{\bra a V(X) \ket a}
      \sqrt{\bra a \cov(X,Y) {V(Y)}^{-1} \cov(Y,X) \ket a}} \leq 1\]
  We thus get for all $a$ such that $\bra a V(X) \ket a > 0$:
  \[ \bra a \cov(X,Y) {V(Y)}^{-1} \cov(Y,X) \ket a < \bra a V(X) \ket a\]
  As for other $a$, both terms are 0, this inequality holds for all $a$, thus
  the theorem holds.
\end{proof}



\section{First order approximation}


\end{document}
